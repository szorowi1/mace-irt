{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9882b96c-b11d-4dec-b4c4-fee41a297dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame, concat, read_csv\n",
    "sns.set_theme(style='white', context='notebook', font_scale=1.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0580cc-e96f-44fa-873d-36b89a833640",
   "metadata": {},
   "source": [
    "## Section 2: Factor Loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e6331f-6a0b-4977-a304-04804361b358",
   "metadata": {},
   "source": [
    "#### Model 2a [Bifactor w/ 10 groups, joint data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3abe030e-e0aa-41b0-b6e5-68d74aa4ac86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>col</th>\n",
       "      <th colspan=\"5\" halign=\"left\">0</th>\n",
       "      <th colspan=\"5\" halign=\"left\">1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>subscale</th>\n",
       "      <th>item</th>\n",
       "      <th>uni</th>\n",
       "      <th>general</th>\n",
       "      <th>group</th>\n",
       "      <th>subscale</th>\n",
       "      <th>item</th>\n",
       "      <th>uni</th>\n",
       "      <th>general</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PVA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.330</td>\n",
       "      <td>EN</td>\n",
       "      <td>43</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.440</td>\n",
       "      <td></td>\n",
       "      <td>52</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.042</td>\n",
       "      <td>PN</td>\n",
       "      <td>44</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.100</td>\n",
       "      <td></td>\n",
       "      <td>45</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPhysA</td>\n",
       "      <td>6</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.440</td>\n",
       "      <td></td>\n",
       "      <td>46</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.250</td>\n",
       "      <td></td>\n",
       "      <td>47</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.250</td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NVEA</td>\n",
       "      <td>5</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.075</td>\n",
       "      <td>WSV</td>\n",
       "      <td>15</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>40</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.015</td>\n",
       "      <td></td>\n",
       "      <td>17</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>41</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.067</td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>48</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.580</td>\n",
       "      <td>WIPV</td>\n",
       "      <td>21</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>49</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.580</td>\n",
       "      <td></td>\n",
       "      <td>24</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>50</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.310</td>\n",
       "      <td>PeerVA</td>\n",
       "      <td>26</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SexA</td>\n",
       "      <td>12</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.110</td>\n",
       "      <td></td>\n",
       "      <td>27</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.092</td>\n",
       "      <td></td>\n",
       "      <td>28</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.250</td>\n",
       "      <td></td>\n",
       "      <td>29</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>36</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.270</td>\n",
       "      <td></td>\n",
       "      <td>30</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EN</td>\n",
       "      <td>38</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.250</td>\n",
       "      <td>PeerPhysA</td>\n",
       "      <td>31</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>39</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.290</td>\n",
       "      <td></td>\n",
       "      <td>32</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>42</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.280</td>\n",
       "      <td></td>\n",
       "      <td>33</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col        0                                     1                           \n",
       "    subscale item    uni general  group   subscale item    uni general  group\n",
       "row                                                                          \n",
       "0        PVA    1  0.840   0.830  0.330         EN   43  0.390   0.390  0.260\n",
       "1               2  0.860   0.830  0.440              52  0.590   0.610  0.180\n",
       "2               3  0.840   0.870  0.042         PN   44  0.580   0.500  0.480\n",
       "3               4  0.670   0.690  0.100              45  0.540   0.440  0.530\n",
       "4     PPhysA    6  0.760   0.780  0.440              46  0.690   0.700  0.170\n",
       "5               7  0.740   0.740  0.250              47  0.680   0.680  0.110\n",
       "6               9  0.480   0.470  0.250              51  0.500   0.490  0.410\n",
       "7       NVEA    5  0.610   0.620  0.075        WSV   15  0.680   0.710  0.078\n",
       "8              40  0.700   0.710  0.015              17  0.630   0.630  0.150\n",
       "9              41  0.720   0.750  0.067              18  0.600   0.600  0.170\n",
       "10             48  0.540   0.540  0.580       WIPV   21  0.640   0.640  0.320\n",
       "11             49  0.570   0.560  0.580              24  0.610   0.610  0.340\n",
       "12             50  0.520   0.510  0.310     PeerVA   26  0.580   0.460  0.730\n",
       "13      SexA   12  0.690   0.700  0.110              27  0.540   0.370  0.800\n",
       "14             13  0.660   0.680  0.092              28  0.510   0.420  0.630\n",
       "15             19  0.540   0.540  0.250              29  0.430   0.330  0.670\n",
       "16             36  0.460   0.440  0.270              30  0.520   0.460  0.370\n",
       "17        EN   38  0.670   0.680  0.250  PeerPhysA   31  0.580   0.520  0.460\n",
       "18             39  0.600   0.610  0.290              32  0.530   0.480  0.480\n",
       "19             42  0.270   0.250  0.280              33  0.480   0.440  0.440"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import Categorical\n",
    "\n",
    "## Load design data.\n",
    "design = read_csv(os.path.join('data', 'design.csv'), index_col=0)\n",
    "design = design[design.columns[:11]]\n",
    "\n",
    "## Define locally dependent items.\n",
    "ld = [[7,8], [9,10,11], [13,14], [15,16], [19,20], [21,22,23], [24,25], [33,34,35], [36,37]]\n",
    "for ix in ld: design = design.drop(index=ix[1:])\n",
    "    \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load and prepare data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load Stan summary.\n",
    "m1 = read_csv(os.path.join('stan_results', 'teicher2015', 'grmq_m1_summary.tsv'), sep='\\t', index_col=0)\n",
    "m2 = read_csv(os.path.join('stan_results', 'teicher2015', 'grmq_m2_summary.tsv'), sep='\\t', index_col=0)\n",
    "\n",
    "## Extract factor loadings.\n",
    "loadings = np.zeros((len(design), 2)).astype(float)\n",
    "for i, j in np.column_stack([np.where(design)]).T:\n",
    "    loadings[i,int(j > 0)] = m2.loc[f'lambda[{i+1},{j+1}]','Mean']\n",
    "     \n",
    "## Merge with unidimensional model.\n",
    "loadings = np.column_stack([\n",
    "    m1.T.filter(regex='lambda').T['Mean'].values,\n",
    "    loadings\n",
    "])\n",
    "        \n",
    "## Convert to DataFrame.\n",
    "design = design.drop(columns='general')\n",
    "loadings = DataFrame(loadings, columns=['uni','general', 'group'])\n",
    "loadings.insert(0, 'item', design.index)\n",
    "loadings.insert(0, 'subscale', design.columns[np.where(design.values)[-1]])\n",
    "\n",
    "## Sort DataFrame.\n",
    "cols = ['PVA','PPhysA','NVEA','SexA','EN','PN','WSV','WIPV','PeerVA','PeerPhysA']\n",
    "loadings['subscale'] = Categorical(loadings.subscale, categories=cols, ordered=True)\n",
    "loadings = loadings.sort_values(['subscale','item'])\n",
    "\n",
    "## Format columns.\n",
    "loadings['item'] = loadings.item.apply(lambda x: '%0.0f' %x)\n",
    "loadings['uni'] = loadings.uni.apply(lambda x: '%0.3f' %x)\n",
    "loadings['general'] = loadings.general.apply(lambda x: '%0.3f' %x)\n",
    "loadings['group'] = loadings.group.apply(lambda x: '%0.3f' %x)\n",
    "\n",
    "## Convert to pivot table.\n",
    "aggfunc = lambda x: ''.join(x)\n",
    "loadings.insert(0, 'col', np.arange(len(loadings)) // 20)\n",
    "loadings.insert(0, 'row', np.arange(len(loadings)) % 20)\n",
    "loadings = loadings.pivot_table(['subscale','item','uni','general','group'], 'row', 'col', aggfunc=aggfunc).fillna('')\n",
    "loadings['subscale'] = loadings['subscale'].apply(lambda x: np.where(x == np.roll(x,1), '', x))\n",
    "\n",
    "## Sort columns.\n",
    "loadings = loadings[['subscale', 'item','uni','general','group']]\n",
    "loadings = loadings.swaplevel(0, 1, 1)\n",
    "loadings = loadings[[0,1]]\n",
    "\n",
    "## Display table.\n",
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21035c23-d462-49db-8462-584943487048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "       0 & \\multicolumn{5}{l}{1} \\\\\n",
      "subscale & item &   uni & general & group &  subscale & item &   uni & general & group \\\\\n",
      "     PVA &    1 & 0.840 &   0.830 & 0.330 &        EN &   43 & 0.390 &   0.390 & 0.260 \\\\\n",
      "\\midrule\n",
      "         &    2 & 0.860 &   0.830 & 0.440 &           &   52 & 0.590 &   0.610 & 0.180 \\\\\n",
      "         &    3 & 0.840 &   0.870 & 0.042 &        PN &   44 & 0.580 &   0.500 & 0.480 \\\\\n",
      "         &    4 & 0.670 &   0.690 & 0.100 &           &   45 & 0.540 &   0.440 & 0.530 \\\\\n",
      "  PPhysA &    6 & 0.760 &   0.780 & 0.440 &           &   46 & 0.690 &   0.700 & 0.170 \\\\\n",
      "         &    7 & 0.740 &   0.740 & 0.250 &           &   47 & 0.680 &   0.680 & 0.110 \\\\\n",
      "         &    9 & 0.480 &   0.470 & 0.250 &           &   51 & 0.500 &   0.490 & 0.410 \\\\\n",
      "    NVEA &    5 & 0.610 &   0.620 & 0.075 &       WSV &   15 & 0.680 &   0.710 & 0.078 \\\\\n",
      "         &   40 & 0.700 &   0.710 & 0.015 &           &   17 & 0.630 &   0.630 & 0.150 \\\\\n",
      "         &   41 & 0.720 &   0.750 & 0.067 &           &   18 & 0.600 &   0.600 & 0.170 \\\\\n",
      "         &   48 & 0.540 &   0.540 & 0.580 &      WIPV &   21 & 0.640 &   0.640 & 0.320 \\\\\n",
      "         &   49 & 0.570 &   0.560 & 0.580 &           &   24 & 0.610 &   0.610 & 0.340 \\\\\n",
      "         &   50 & 0.520 &   0.510 & 0.310 &    PeerVA &   26 & 0.580 &   0.460 & 0.730 \\\\\n",
      "    SexA &   12 & 0.690 &   0.700 & 0.110 &           &   27 & 0.540 &   0.370 & 0.800 \\\\\n",
      "         &   13 & 0.660 &   0.680 & 0.092 &           &   28 & 0.510 &   0.420 & 0.630 \\\\\n",
      "         &   19 & 0.540 &   0.540 & 0.250 &           &   29 & 0.430 &   0.330 & 0.670 \\\\\n",
      "         &   36 & 0.460 &   0.440 & 0.270 &           &   30 & 0.520 &   0.460 & 0.370 \\\\\n",
      "      EN &   38 & 0.670 &   0.680 & 0.250 & PeerPhysA &   31 & 0.580 &   0.520 & 0.460 \\\\\n",
      "         &   39 & 0.600 &   0.610 & 0.290 &           &   32 & 0.530 &   0.480 & 0.480 \\\\\n",
      "         &   42 & 0.270 &   0.250 & 0.280 &           &   33 & 0.480 &   0.440 & 0.440 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(loadings.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135c8042-9917-42d0-873b-b3098d429507",
   "metadata": {},
   "source": [
    "## Section 3: Variance Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b464a99d-c191-40f3-a85d-df821baa1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load design data.\n",
    "design = read_csv(os.path.join('data', 'design.csv'), index_col=0)\n",
    "\n",
    "## Define locally dependent items.\n",
    "ld = [[7,8], [9,10,11], [13,14], [15,16], [19,20], [21,22,23], [24,25], [33,34,35], [36,37]]\n",
    "for ix in ld: design = design.drop(index=ix[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f00a5e5-b7d2-4e22-adeb-b35a7ac03a67",
   "metadata": {},
   "source": [
    "### 3.1 Bifactor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41df98d6-5060-443b-9160-44679546b8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>study</th>\n",
       "      <th colspan=\"4\" halign=\"left\">1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ecv</th>\n",
       "      <th>omega</th>\n",
       "      <th>omega_s</th>\n",
       "      <th>H</th>\n",
       "      <th>ecv</th>\n",
       "      <th>omega</th>\n",
       "      <th>omega_s</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subscale</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>general</th>\n",
       "      <td>0.717</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PVA</th>\n",
       "      <td></td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.272</td>\n",
       "      <td></td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPhysA</th>\n",
       "      <td></td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.272</td>\n",
       "      <td></td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVEA</th>\n",
       "      <td></td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.531</td>\n",
       "      <td></td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SexA</th>\n",
       "      <td></td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.142</td>\n",
       "      <td></td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td></td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.259</td>\n",
       "      <td></td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PN</th>\n",
       "      <td></td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.483</td>\n",
       "      <td></td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSV</th>\n",
       "      <td></td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.056</td>\n",
       "      <td></td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WIPV</th>\n",
       "      <td></td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.197</td>\n",
       "      <td></td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PeerVA</th>\n",
       "      <td></td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.82</td>\n",
       "      <td></td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PeerPhysA</th>\n",
       "      <td></td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.447</td>\n",
       "      <td></td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "study          1                            2                      \n",
       "             ecv  omega omega_s      H    ecv  omega omega_s      H\n",
       "subscale                                                           \n",
       "general    0.717  0.966   0.928  0.966  0.696  0.967   0.927  0.963\n",
       "PVA               0.912   0.068  0.272         0.892   0.158  0.472\n",
       "PPhysA            0.788   0.144  0.272         0.787   0.228  0.373\n",
       "NVEA              0.848   0.138  0.531         0.828   0.119  0.425\n",
       "SexA              0.717   0.061  0.142         0.753   0.292  0.454\n",
       "EN                0.712   0.141  0.259         0.876   0.203  0.542\n",
       "PN                0.803   0.215  0.483         0.817   0.117  0.289\n",
       "WSV                 0.7   0.028  0.056         0.663   0.037  0.068\n",
       "WIPV              0.666   0.145  0.197         0.623   0.083  0.116\n",
       "PeerVA            0.878   0.624   0.82         0.851   0.569  0.766\n",
       "PeerPhysA         0.704   0.337  0.447         0.702   0.344  0.455"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Define I/O parameters.\n",
    "studies = ['teicher2015', 'tuominen2022']\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Restrict to columns of interest.\n",
    "D = design[design.columns[:11]].copy()\n",
    "\n",
    "stats = []\n",
    "for study in studies:\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Load and prepare data.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    ## Load Stan summary.\n",
    "    summary = read_csv(os.path.join('stan_results', study, 'grmq_m2_summary.tsv'), sep='\\t', index_col=0)\n",
    "    \n",
    "    ## Extract factor loadings.\n",
    "    loadings = np.zeros_like(D).astype(float)\n",
    "    for i, j in np.column_stack([np.where(D)]).T:\n",
    "        loadings[i,j] = summary.loc[f'lambda[{i+1},{j+1}]','Mean']\n",
    "        \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Coefficient omega hierachical.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        \n",
    "    ## Preallocate space.\n",
    "    omega   = np.zeros(len(D.columns))\n",
    "    omega_s = np.zeros(len(D.columns))\n",
    "        \n",
    "    ## Iterate over factors.\n",
    "    for i, col in enumerate(D.columns):\n",
    "        \n",
    "        ## Restrict to items in group.\n",
    "        L = loadings[D[col]==1]\n",
    "        \n",
    "        ## Compute squared sum of factor loadings.\n",
    "        A = np.square(np.sum(L, axis=0))\n",
    "        \n",
    "        ## Compute sum of error variances.\n",
    "        B = np.sum(1 - np.square(L).sum(axis=1))\n",
    "        \n",
    "        ## Compute total variance.\n",
    "        C = np.sum(A) + B\n",
    "        \n",
    "        ## Compute coefficient omega.\n",
    "        omega[i] = A.sum() / C\n",
    "        \n",
    "        ## Compute coefficient omega subscale.\n",
    "        omega_s[i] = A[i] / C\n",
    "        \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Explained common variance.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        \n",
    "    ## Compute sum of squares.\n",
    "    ss = np.square(loadings).sum(axis=0)\n",
    "    \n",
    "    ## Compute explained common variance.\n",
    "    ecv = ss / ss.sum()\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### H-index\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    ## Preallocate space.\n",
    "    H = np.zeros(len(D.columns))\n",
    "    \n",
    "    ## Iterate over factors.\n",
    "    for i, col in enumerate(D.columns):\n",
    "        \n",
    "        ## Compute squared loadings.\n",
    "        s = np.square(loadings[:,i])\n",
    "        \n",
    "        ## Compute H-index.\n",
    "        H[i] = 1. / (1 + 1 / np.sum(s / (1-s)))\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Convert to DataFrame.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    stats.append(DataFrame(dict(\n",
    "        subscale = D.columns,\n",
    "        study = np.repeat(study, D.columns.size),\n",
    "        ecv = ecv,\n",
    "        omega = omega,\n",
    "        omega_s = omega_s,\n",
    "        H = H\n",
    "    )))\n",
    "    \n",
    "## Concatenate DataFrames.\n",
    "stats = concat(stats).replace({'teicher2015':1, 'tuominen2022': 2})\n",
    "\n",
    "## Convert to pivot table.\n",
    "stats = stats.pivot_table(['omega','omega_s','ecv','H'], 'subscale', 'study').round(3)\n",
    "stats = stats.astype(str)\n",
    "stats.loc[stats.index!='general','ecv'] = ''\n",
    "\n",
    "## Re-organize rows.\n",
    "index = ['general', 'PVA', 'PPhysA', 'NVEA', 'SexA', 'EN', 'PN', 'WSV', 'WIPV', 'PeerVA', 'PeerPhysA']\n",
    "stats = stats.loc[index]\n",
    "\n",
    "## Re-organize columns.\n",
    "cols = [(1,'ecv'),(1,'omega'),(1,'omega_s'),(1,'H'),(2,'ecv'),(2,'omega'),(2,'omega_s'),(2,'H')]\n",
    "stats = stats.swaplevel(axis='columns')[cols]\n",
    "\n",
    "## Display table.\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd3922a2-75e2-4273-8a20-a637bbdf22c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "study & \\multicolumn{4}{l}{1} & \\multicolumn{4}{l}{2} \\\\\n",
      "{} &    ecv &  omega & omega\\_s &      H &    ecv &  omega & omega\\_s &      H \\\\\n",
      "subscale  &        &        &         &        &        &        &         &        \\\\\n",
      "\\midrule\n",
      "general   &  0.717 &  0.966 &   0.928 &  0.966 &  0.696 &  0.967 &   0.927 &  0.963 \\\\\n",
      "PVA       &        &  0.912 &   0.068 &  0.272 &        &  0.892 &   0.158 &  0.472 \\\\\n",
      "PPhysA    &        &  0.788 &   0.144 &  0.272 &        &  0.787 &   0.228 &  0.373 \\\\\n",
      "NVEA      &        &  0.848 &   0.138 &  0.531 &        &  0.828 &   0.119 &  0.425 \\\\\n",
      "SexA      &        &  0.717 &   0.061 &  0.142 &        &  0.753 &   0.292 &  0.454 \\\\\n",
      "EN        &        &  0.712 &   0.141 &  0.259 &        &  0.876 &   0.203 &  0.542 \\\\\n",
      "PN        &        &  0.803 &   0.215 &  0.483 &        &  0.817 &   0.117 &  0.289 \\\\\n",
      "WSV       &        &    0.7 &   0.028 &  0.056 &        &  0.663 &   0.037 &  0.068 \\\\\n",
      "WIPV      &        &  0.666 &   0.145 &  0.197 &        &  0.623 &   0.083 &  0.116 \\\\\n",
      "PeerVA    &        &  0.878 &   0.624 &   0.82 &        &  0.851 &   0.569 &  0.766 \\\\\n",
      "PeerPhysA &        &  0.704 &   0.337 &  0.447 &        &  0.702 &   0.344 &  0.455 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(stats.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090511d-3aed-4a76-9f5c-32ead715b3fa",
   "metadata": {},
   "source": [
    "### 3.2 Bifactor S-1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ea5195b-2b40-4d3d-a18d-dd96fedc46fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>study</th>\n",
       "      <th colspan=\"4\" halign=\"left\">1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ecv</th>\n",
       "      <th>omega</th>\n",
       "      <th>omega_s</th>\n",
       "      <th>H</th>\n",
       "      <th>ecv</th>\n",
       "      <th>omega</th>\n",
       "      <th>omega_s</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>general</th>\n",
       "      <td>0.747</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peer</th>\n",
       "      <td></td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.843</td>\n",
       "      <td></td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reverse</th>\n",
       "      <td></td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.735</td>\n",
       "      <td></td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "study        1                            2                      \n",
       "           ecv  omega omega_s      H    ecv  omega omega_s      H\n",
       "general  0.747  0.963   0.902  0.967  0.758  0.963   0.909  0.963\n",
       "peer            0.888   0.574  0.843         0.869   0.502  0.788\n",
       "reverse         0.839   0.579  0.735         0.917   0.492  0.773"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Define I/O parameters.\n",
    "studies = ['teicher2015', 'tuominen2022']\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Restrict to columns of interest.\n",
    "D = design[['general','peer','reverse']].copy()\n",
    "\n",
    "stats = []\n",
    "for study in studies:\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Load and prepare data.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    ## Load Stan summary.\n",
    "    summary = read_csv(os.path.join('stan_results', study, 'grmq_m3_summary.tsv'), sep='\\t', index_col=0)\n",
    "    \n",
    "    ## Extract factor loadings.\n",
    "    loadings = np.zeros_like(D).astype(float)\n",
    "    for i, j in np.column_stack([np.where(D)]).T:\n",
    "        loadings[i,j] = summary.loc[f'lambda[{i+1},{j+1}]','Mean']\n",
    "        \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Coefficient omega hierachical.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        \n",
    "    ## Preallocate space.\n",
    "    omega   = np.zeros(len(D.columns))\n",
    "    omega_s = np.zeros(len(D.columns))\n",
    "        \n",
    "    ## Iterate over factors.\n",
    "    for i, col in enumerate(D.columns):\n",
    "        \n",
    "        ## Restrict to items in group.\n",
    "        L = loadings[D[col]==1]\n",
    "        \n",
    "        ## Compute squared sum of factor loadings.\n",
    "        A = np.square(np.sum(L, axis=0))\n",
    "        \n",
    "        ## Compute sum of error variances.\n",
    "        B = np.sum(1 - np.square(L).sum(axis=1))\n",
    "        \n",
    "        ## Compute total variance.\n",
    "        C = np.sum(A) + B\n",
    "        \n",
    "        ## Compute coefficient omega.\n",
    "        omega[i] = A.sum() / C\n",
    "        \n",
    "        ## Compute coefficient omega subscale.\n",
    "        omega_s[i] = A[i] / C\n",
    "        \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Explained common variance.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        \n",
    "    ## Compute sum of squares.\n",
    "    ss = np.square(loadings).sum(axis=0)\n",
    "    \n",
    "    ## Compute explained common variance.\n",
    "    ecv = ss / ss.sum()\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### H-index\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    ## Preallocate space.\n",
    "    H = np.zeros(len(D.columns))\n",
    "    \n",
    "    ## Iterate over factors.\n",
    "    for i, col in enumerate(D.columns):\n",
    "        \n",
    "        ## Compute squared loadings.\n",
    "        s = np.square(loadings[:,i])\n",
    "        \n",
    "        ## Compute H-index.\n",
    "        H[i] = 1. / (1 + 1 / np.sum(s / (1-s)))\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Convert to DataFrame.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    stats.append(DataFrame(dict(\n",
    "        subscale = D.columns,\n",
    "        study = np.repeat(study, D.columns.size),\n",
    "        ecv = ecv,\n",
    "        omega = omega,\n",
    "        omega_s = omega_s,\n",
    "        H = H\n",
    "    )))\n",
    "    \n",
    "## Concatenate DataFrames.\n",
    "stats = concat(stats).replace({'teicher2015':1, 'tuominen2022': 2})\n",
    "\n",
    "## Convert to pivot table.\n",
    "stats = stats.pivot_table(['omega','omega_s','ecv','H'], 'subscale', 'study').round(3)\n",
    "stats = stats.astype(str)\n",
    "stats.loc[stats.index!='general','ecv'] = ''\n",
    "\n",
    "## Re-organize rows.\n",
    "index = D.columns\n",
    "stats = stats.loc[index]\n",
    "\n",
    "## Re-organize columns.\n",
    "cols = [(1,'ecv'),(1,'omega'),(1,'omega_s'),(1,'H'),(2,'ecv'),(2,'omega'),(2,'omega_s'),(2,'H')]\n",
    "stats = stats.swaplevel(axis='columns')[cols]\n",
    "\n",
    "## Display table.\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a35f79c5-999b-4ec9-bca7-e5d304285f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "study & \\multicolumn{4}{l}{1} & \\multicolumn{4}{l}{2} \\\\\n",
      "{} &    ecv &  omega & omega\\_s &      H &    ecv &  omega & omega\\_s &      H \\\\\n",
      "\\midrule\n",
      "general &  0.747 &  0.963 &   0.902 &  0.967 &  0.758 &  0.963 &   0.909 &  0.963 \\\\\n",
      "peer    &        &  0.888 &   0.574 &  0.843 &        &  0.869 &   0.502 &  0.788 \\\\\n",
      "reverse &        &  0.839 &   0.579 &  0.735 &        &  0.917 &   0.492 &  0.773 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(stats.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
